#!/bin/bash

# åä¸ºæ˜‡è…¾NPUè½¨è¿¹é¢„è®­ç»ƒ+å¾®è°ƒå®Œæ•´è®­ç»ƒè„šæœ¬
# ä½¿ç”¨æ–¹æ³•ï¼š
# 1. åªé¢„è®­ç»ƒï¼š./run_training_npu.sh pretrain
# 2. åªå¾®è°ƒï¼š./run_training_npu.sh finetune /path/to/pretrained/model
# 3. å®Œæ•´æµç¨‹ï¼ˆé¢„è®­ç»ƒ+å¾®è°ƒï¼‰ï¼š./run_training_npu.sh full

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é…ç½®å‚æ•°
BASE_DIR="/home/maomao/project/token_for_nj"
OUTPUT_BASE="../model_out"
PRETRAIN_OUTPUT="$OUTPUT_BASE/trajectory_pretrain_model_npu"
FINETUNE_OUTPUT="$OUTPUT_BASE/trajectory_finetune_model_npu"
LOG_DIR="$OUTPUT_BASE/logs"

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p "$LOG_DIR"

# è·å–å½“å‰æ—¶é—´æˆ³
TIMESTAMP=$(date "+%Y%m%d_%H%M%S")

# æ£€æŸ¥NPUç¯å¢ƒ
check_npu_environment() {
    echo "æ£€æŸ¥NPUç¯å¢ƒ..."
    
    # æ£€æŸ¥npu-smiå‘½ä»¤æ˜¯å¦å¯ç”¨
    if ! command -v npu-smi &> /dev/null; then
        echo "é”™è¯¯: npu-smi å‘½ä»¤ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ˜‡è…¾é©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…"
        exit 1
    fi
    
    # æ£€æŸ¥NPUè®¾å¤‡
    NPU_COUNT=$(npu-smi info | grep "NPU" | wc -l)
    if [ "$NPU_COUNT" -eq 0 ]; then
        echo "é”™è¯¯: æœªæ£€æµ‹åˆ°NPUè®¾å¤‡"
        exit 1
    fi
    
    echo "æ£€æµ‹åˆ° $NPU_COUNT ä¸ªNPUè®¾å¤‡"
    npu-smi info
    
    # æ£€æŸ¥Pythonç¯å¢ƒå’ŒNPUç›¸å…³åŒ…
    if ! python -c "import torch, torch_npu, transformers" > /dev/null 2>&1; then
        echo "é”™è¯¯: ç¼ºå°‘å¿…è¦çš„PythonåŒ… (torch, torch_npu, transformers)"
        echo "è¯·å…ˆå®‰è£…NPUç‰ˆæœ¬çš„PyTorchå’Œç›¸å…³ä¾èµ–"
        exit 1
    fi
    
    echo "NPUç¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# è®¾ç½®NPUç¯å¢ƒå˜é‡
setup_npu_env() {
    # è®¾ç½®NPUç›¸å…³ç¯å¢ƒå˜é‡
    export ASCEND_RT_PATH="/usr/local/Ascend/nnae/latest"
    export PATH="/usr/local/Ascend/nnae/latest/bin:/usr/local/Ascend/nnae/latest/compiler/bin:$PATH"
    export PYTHONPATH="/usr/local/Ascend/nnae/latest/python/site-packages:$PYTHONPATH"
    export LD_LIBRARY_PATH="/usr/local/Ascend/nnae/latest/lib:$LD_LIBRARY_PATH"
    export ASCEND_OPP_PATH="/usr/local/Ascend/nnae/latest/opp"
    export ASCEND_AICPU_PATH="/usr/local/Ascend/nnae/latest"
    export ASCEND_TENSOR_COMPILER_INCLUDE="/usr/local/Ascend/nnae/latest/include"
    
    # è®¾ç½®HCCLç›¸å…³ç¯å¢ƒå˜é‡
    export HCCL_CONNECT_TIMEOUT=1800
    export HCCL_EXEC_TIMEOUT=1800
    
    # ä¼˜åŒ–NPUæ€§èƒ½
    export TASK_QUEUE_ENABLE=1
    export PTCOPY_ENABLE=1
    export COMBINED_ENABLE=1
    export ACL_DUMP_DATA=0  # ç”Ÿäº§ç¯å¢ƒå…³é—­dump
    
    echo "NPUç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ"
}

echo "=== åä¸ºæ˜‡è…¾NPUè½¨è¿¹æ¨¡å‹è®­ç»ƒè„šæœ¬ ==="
echo "æ—¶é—´: $(date)"
echo "åŸºç¡€ç›®å½•: $BASE_DIR"
echo "æ—¥å¿—ç›®å½•: $LOG_DIR"

# è¿›å…¥å·¥ä½œç›®å½•
cd "$BASE_DIR"

# æ£€æŸ¥å¹¶è®¾ç½®NPUç¯å¢ƒ
check_npu_environment
setup_npu_env

function run_pretraining_npu() {
    echo ""
    echo "==================="
    echo "å¼€å§‹NPUé¢„è®­ç»ƒé˜¶æ®µ"
    echo "==================="
    
    local log_file="$LOG_DIR/pretrain_npu_$TIMESTAMP.log"
    echo "NPUé¢„è®­ç»ƒæ—¥å¿—: $log_file"
    echo "NPUé¢„è®­ç»ƒæ¨¡å‹ä¿å­˜è·¯å¾„: $PRETRAIN_OUTPUT"
    
    # æ£€æŸ¥NPUæ•°é‡å†³å®šæ˜¯å¦ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
    NPU_COUNT=$(npu-smi info | grep "NPU" | wc -l)
    if [ "$NPU_COUNT" -gt 1 ]; then
        echo "æ£€æµ‹åˆ° $NPU_COUNT ä¸ªNPUï¼Œä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ"
        
        # NPUåˆ†å¸ƒå¼é¢„è®­ç»ƒ
        python -m torch.distributed.launch \
            --nproc_per_node=$NPU_COUNT \
            --master_port=29500 \
            --use_env \
            train_pretrain_npu.py \
            2>&1 | tee "$log_file"
    else
        echo "ä½¿ç”¨å•NPUè®­ç»ƒ"
        
        # å•NPUé¢„è®­ç»ƒ
        python train_pretrain_npu.py \
            2>&1 | tee "$log_file"
    fi
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ˜¯å¦æˆåŠŸ
    if [ -d "$PRETRAIN_OUTPUT/final_model" ]; then
        echo "âœ… NPUé¢„è®­ç»ƒæˆåŠŸå®Œæˆ"
        echo "é¢„è®­ç»ƒæ¨¡å‹ä¿å­˜åœ¨: $PRETRAIN_OUTPUT/final_model"
        
        # æ˜¾ç¤ºæ¨¡å‹æ–‡ä»¶
        echo "æ¨¡å‹æ–‡ä»¶åˆ—è¡¨:"
        ls -la "$PRETRAIN_OUTPUT/final_model/"
        
        # æ˜¾ç¤ºNPUè®¾å¤‡çŠ¶æ€
        echo "è®­ç»ƒå®ŒæˆåNPUçŠ¶æ€:"
        npu-smi info -t power -i 0
    else
        echo "âŒ NPUé¢„è®­ç»ƒå¤±è´¥ï¼Œæœªæ‰¾åˆ°æ¨¡å‹è¾“å‡º"
        exit 1
    fi
}

function run_finetuning_npu() {
    local pretrained_path="$1"
    
    echo ""
    echo "==================="
    echo "å¼€å§‹NPUå¾®è°ƒé˜¶æ®µ"
    echo "==================="
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹æ˜¯å¦å­˜åœ¨
    if [ ! -d "$pretrained_path" ]; then
        echo "é”™è¯¯: é¢„è®­ç»ƒæ¨¡å‹ä¸å­˜åœ¨: $pretrained_path"
        echo "è¯·å…ˆè¿è¡ŒNPUé¢„è®­ç»ƒæˆ–æä¾›æ­£ç¡®çš„é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„"
        exit 1
    fi
    
    local log_file="$LOG_DIR/finetune_npu_$TIMESTAMP.log"
    echo "NPUå¾®è°ƒæ—¥å¿—: $log_file"
    echo "é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„: $pretrained_path"
    echo "NPUå¾®è°ƒæ¨¡å‹ä¿å­˜è·¯å¾„: $FINETUNE_OUTPUT"
    
    # æ£€æŸ¥NPUæ•°é‡å†³å®šæ˜¯å¦ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
    NPU_COUNT=$(npu-smi info | grep "NPU" | wc -l)
    if [ "$NPU_COUNT" -gt 1 ]; then
        echo "æ£€æµ‹åˆ° $NPU_COUNT ä¸ªNPUï¼Œä½¿ç”¨åˆ†å¸ƒå¼å¾®è°ƒ"
        
        # NPUåˆ†å¸ƒå¼å¾®è°ƒ
        python -m torch.distributed.launch \
            --nproc_per_node=$NPU_COUNT \
            --master_port=29501 \
            --use_env \
            train_finetune_npu.py \
            --pretrained_model_path "$pretrained_path" \
            2>&1 | tee "$log_file"
    else
        echo "ä½¿ç”¨å•NPUå¾®è°ƒ"
        
        # å•NPUå¾®è°ƒ
        python train_finetune_npu.py \
            --pretrained_model_path "$pretrained_path" \
            2>&1 | tee "$log_file"
    fi
    
    # æ£€æŸ¥å¾®è°ƒæ˜¯å¦æˆåŠŸ
    if [ -d "$FINETUNE_OUTPUT/best_model" ]; then
        echo "âœ… NPUå¾®è°ƒæˆåŠŸå®Œæˆ"
        echo "æœ€ç»ˆæ¨¡å‹ä¿å­˜åœ¨: $FINETUNE_OUTPUT/best_model"
        
        # æ˜¾ç¤ºæ¨¡å‹æ–‡ä»¶
        echo "æ¨¡å‹æ–‡ä»¶åˆ—è¡¨:"
        ls -la "$FINETUNE_OUTPUT/best_model/"
        
        # å¦‚æœæœ‰éªŒè¯æŠ¥å‘Šï¼Œæ˜¾ç¤ºå…³é”®æŒ‡æ ‡
        if [ -f "$FINETUNE_OUTPUT/best_model/validation_report.json" ]; then
            echo ""
            echo "éªŒè¯ç»“æœæ‘˜è¦:"
            python -c "
import json
with open('$FINETUNE_OUTPUT/best_model/validation_report.json') as f:
    report = json.load(f)
    print(f\"æ•´ä½“å‡†ç¡®ç‡: {report.get('accuracy', 'N/A'):.4f}\")
    print(f\"å®å¹³å‡F1: {report.get('macro avg', {}).get('f1-score', 'N/A'):.4f}\")
    print(f\"åŠ æƒå¹³å‡F1: {report.get('weighted avg', {}).get('f1-score', 'N/A'):.4f}\")
"
        fi
        
        # æ˜¾ç¤ºNPUè®¾å¤‡çŠ¶æ€
        echo "è®­ç»ƒå®ŒæˆåNPUçŠ¶æ€:"
        npu-smi info -t power -i 0
    else
        echo "âŒ NPUå¾®è°ƒå¤±è´¥ï¼Œæœªæ‰¾åˆ°æ¨¡å‹è¾“å‡º"
        exit 1
    fi
}

function show_usage() {
    echo "ç”¨æ³•: $0 <mode> [pretrained_model_path]"
    echo ""
    echo "æ¨¡å¼:"
    echo "  pretrain              - åªè¿è¡ŒNPUé¢„è®­ç»ƒ"
    echo "  finetune <model_path> - åªè¿è¡ŒNPUå¾®è°ƒï¼Œéœ€è¦æŒ‡å®šé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„"
    echo "  full                  - è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆNPUé¢„è®­ç»ƒ + NPUå¾®è°ƒï¼‰"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0 pretrain"
    echo "  $0 finetune ../model_out/trajectory_pretrain_model_npu/best_model"
    echo "  $0 full"
    echo ""
    echo "NPUç¯å¢ƒè¦æ±‚:"
    echo "  - åä¸ºæ˜‡è…¾NPUè®¾å¤‡"
    echo "  - CANNé©±åŠ¨å’Œå·¥å…·é“¾"
    echo "  - torch_npuåº“"
}

function check_npu_resources() {
    echo ""
    echo "NPUèµ„æºä½¿ç”¨æƒ…å†µ:"
    npu-smi info
    echo ""
    echo "NPUå†…å­˜ä½¿ç”¨æƒ…å†µ:"
    npu-smi info -t usages -i 0
}

# ä¸»é€»è¾‘
case "$1" in
    "pretrain")
        run_pretraining_npu
        echo ""
        echo "ğŸ‰ NPUé¢„è®­ç»ƒå®Œæˆï¼"
        echo "æ¥ä¸‹æ¥å¯ä»¥è¿è¡ŒNPUå¾®è°ƒ: $0 finetune $PRETRAIN_OUTPUT/final_model"
        check_npu_resources
        ;;
    
    "finetune")
        if [ -z "$2" ]; then
            echo "é”™è¯¯: å¾®è°ƒæ¨¡å¼éœ€è¦æŒ‡å®šé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„"
            show_usage
            exit 1
        fi
        run_finetuning_npu "$2"
        echo ""
        echo "ğŸ‰ NPUå¾®è°ƒå®Œæˆï¼"
        echo "æœ€ç»ˆæ¨¡å‹å¯ç”¨äºæ¨ç†: $FINETUNE_OUTPUT/best_model"
        check_npu_resources
        ;;
    
    "full")
        echo "è¿è¡Œå®Œæ•´NPUè®­ç»ƒæµç¨‹ï¼šé¢„è®­ç»ƒ -> å¾®è°ƒ"
        
        # 1. NPUé¢„è®­ç»ƒ
        run_pretraining_npu
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©NPUè®¾å¤‡å†·å´
        echo "ç­‰å¾…NPUè®¾å¤‡å†·å´..."
        sleep 30
        
        # 2. NPUå¾®è°ƒ
        run_finetuning_npu "$PRETRAIN_OUTPUT/final_model"
        
        echo ""
        echo "ğŸ‰ğŸ‰ğŸ‰ å®Œæ•´NPUè®­ç»ƒæµç¨‹å®Œæˆï¼"
        echo "é¢„è®­ç»ƒæ¨¡å‹: $PRETRAIN_OUTPUT/final_model"
        echo "æœ€ç»ˆå¾®è°ƒæ¨¡å‹: $FINETUNE_OUTPUT/best_model"
        check_npu_resources
        ;;
    
    "check")
        echo "æ£€æŸ¥NPUç¯å¢ƒå’Œèµ„æºçŠ¶æ€"
        check_npu_environment
        check_npu_resources
        ;;
    
    *)
        echo "é”™è¯¯: æ— æ•ˆçš„æ¨¡å¼ '$1'"
        show_usage
        exit 1
        ;;
esac

echo ""
echo "è®­ç»ƒå®Œæˆæ—¶é—´: $(date)"
echo "æ‰€æœ‰æ—¥å¿—ä¿å­˜åœ¨: $LOG_DIR/"

# æ˜¾ç¤ºç£ç›˜ä½¿ç”¨æƒ…å†µ
echo ""
echo "æ¨¡å‹æ–‡ä»¶ç£ç›˜ä½¿ç”¨æƒ…å†µ:"
if [ -d "$OUTPUT_BASE" ]; then
    du -sh "$OUTPUT_BASE"/* 2>/dev/null || true
fi

# æ¸…ç†NPUç¼“å­˜
echo ""
echo "æ¸…ç†NPUç¼“å­˜..."
python -c "
try:
    import torch_npu
    if torch_npu.npu.is_available():
        torch_npu.npu.empty_cache()
        print('NPUç¼“å­˜æ¸…ç†å®Œæˆ')
    else:
        print('NPUä¸å¯ç”¨ï¼Œè·³è¿‡ç¼“å­˜æ¸…ç†')
except Exception as e:
    print(f'æ¸…ç†NPUç¼“å­˜æ—¶å‡ºé”™: {e}')
"

echo "NPUè®­ç»ƒè„šæœ¬æ‰§è¡Œå®Œæˆï¼"